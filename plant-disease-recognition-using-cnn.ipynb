{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2394131,"sourceType":"datasetVersion","datasetId":1447507}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"executionInfo":{"elapsed":14288,"status":"ok","timestamp":1691895892525,"user":{"displayName":"sunil thite","userId":"11844998078783788539"},"user_tz":-330},"id":"pwcuykzwBhZC","outputId":"3bef51a3-ffb6-4a3f-e7df-88dcaf792493","execution":{"iopub.status.busy":"2023-09-28T13:50:18.251412Z","iopub.execute_input":"2023-09-28T13:50:18.25192Z","iopub.status.idle":"2023-09-28T13:50:18.256728Z","shell.execute_reply.started":"2023-09-28T13:50:18.251868Z","shell.execute_reply":"2023-09-28T13:50:18.255817Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix , classification_report , auc , accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom PIL import Image\nimport cv2\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense,Dropout,Conv2D, Flatten,MaxPooling2D\nfrom keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"6hKIE1ozBhbn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/plant-disease-recognition-dataset/Train/Train\"\ntrain = image_dataset_from_directory(path, batch_size=32,\n                                    image_size=(256,256),shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/plant-disease-recognition-dataset/Test/Test\"\ntest = image_dataset_from_directory(path, batch_size=32,\n                                    image_size=(256,256),shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/plant-disease-recognition-dataset/Validation/Validation\"\nvalid = image_dataset_from_directory(path, batch_size=32,\n                                    image_size=(256,256),shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = train.class_names\nclass_labels\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train))\nprint(len(test))\nprint(len(valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"for image_batch,image_label in train.take(1):\n    print(image_batch[0])\n    print(class_labels[image_label[0].numpy()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Image Data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor image_batch , image_label in train.take(1):\n    for i in range(20):\n        plt.subplot(5,4,i+1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_labels[image_label[i].numpy()])\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resizing and Rescaling Images","metadata":{}},{"cell_type":"code","source":"resizing_and_rescaling = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(256,256),\n    tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomContrast(0.3),\n    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.3),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creat CNN Model ","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE=256\nCHANNELS=3\nBATCH_SIZE=32\nEPOCHS=10\n\ninput_shape=(BATCH_SIZE , IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n\nmodel= tf.keras.models.Sequential([\n  resizing_and_rescaling,\n  data_augmentation,\n  # Convolution layer 1\n  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),padding='valid',activation='relu',input_shape=input_shape),\n  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    \n  # Convolution layer 2\n  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'),\n  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    \n  # Convolution layer 3  \n  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'),\n  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    \n  # Convolution layer 4  \n  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'),\n  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n  # Flatten Layers\n  tf.keras.layers.Flatten(),\n\n  # Dense layers\n  tf.keras.layers.Dense(units=500,activation='relu'),\n  tf.keras.layers.Dropout(0.4),\n  tf.keras.layers.Dense(units=500,activation='relu'),\n  tf.keras.layers.Dropout(0.3),\n  tf.keras.layers.Dense(units=100,activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(units=3,activation='softmax')\n\n])\n\nmodel.build(input_shape=input_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",\n             loss=\"sparse_categorical_crossentropy\",\n             metrics=[\"accuracy\"])\n\nhistory = model.fit(train ,  batch_size=32 ,epochs=10,\n                verbose=1,\n                validation_data=valid) # epochs=10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose an image from the test dataset\nsample_image, _ = next(iter(test))\n\n# Create a new model to get intermediate layer outputs\nconvolutional_layers_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[6].output)  # Adjust the layer index accordingly\n\n# Get the feature maps for the chosen image\nfeature_maps = convolutional_layers_model.predict(sample_image)\n\n# Plot the feature maps\nplt.figure(figsize=(15, 15))\nfor i in range(32):  # Assuming the first convolutional layer has 32 filters\n    ax = plt.subplot(4, 8, i + 1)\n    plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\n    plt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy and loss on Train and Test","metadata":{}},{"cell_type":"code","source":"loss,acc = model.evaluate(train)\nprint(\"Loss on Train data:\",loss)\nprint(\"Accuracy on Train data:\",acc)\n\nloss1,acc1 = model.evaluate(test)\n\nprint(\"Loss on Test data:\",loss1)\nprint(\"Accuracy on Test data:\",acc1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\n\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS=10\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.plot(range(EPOCHS),acc, label=\"Training Accuracy\")\nplt.plot(range(EPOCHS),val_acc, label=\"Validation Accuracy\")\nplt.legend(loc=\"lower right\")\nplt.title(\"Training and Validation Accuracy\")\n\n#plt.figure(figsize=(6,6))\nplt.subplot(1,2,2)\nplt.plot(range(EPOCHS),loss, label=\"Training Loss\")\nplt.plot(range(EPOCHS),val_loss, label=\"Validation Loss\")\nplt.legend(loc=\"lower right\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Predictions on Test Data","metadata":{}},{"cell_type":"code","source":"def Prediction(model,img):\n    img_array = tf.keras.preprocessing.image.img_to_array((images[i].numpy()))\n    img_array = tf.expand_dims(img_array,0)     # create a batch\n\n    predictions = model.predict(img_array)\n\n    predicted_class = class_labels[np.argmax(predictions[0])]\n    confidence = round(100*(np.max(predictions[0])),2)\n    \n    return predicted_class , confidence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nfor images , labels in test.take(1):\n    for i in range(20):\n        ax = plt.subplot(5,4,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        #plt.title(class_labels[labels[i]])\n\n\n        predicted_class , confidence = Prediction(model,images[i].numpy())\n        actual_class = class_labels[labels[i]]\n        plt.title(f\"Actual:{actual_class}\\n Predicted:{predicted_class}\\n Confidence:{confidence}%\")\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}